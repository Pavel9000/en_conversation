{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"chatbot english conversation.ipynb\"","provenance":[{"file_id":"https://github.com/tensorflow/examples/blob/master/community/en/transformer_chatbot.ipynb","timestamp":1597990235694}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"5N_T6HAD37lp","executionInfo":{"status":"ok","timestamp":1602134411146,"user_tz":-180,"elapsed":24451,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"9c234935-8e24-4814-ec4a-3753118a51ae","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1sN_wiWtxSlg"},"source":["# import bz2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mb_5bl7G_n30","executionInfo":{"status":"ok","timestamp":1602134430872,"user_tz":-180,"elapsed":2865,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["import tensorflow as tf\n","assert tf.__version__.startswith('2')\n","tf.random.set_seed(1234)\n","\n","from tensorflow import keras\n","\n","# !pip install tensorflow-datasets==1.2.0\n","import tensorflow_datasets as tfds\n","\n","import os\n","import re\n","import numpy as np\n","\n","import pandas as pd\n","import json\n","\n","# import matplotlib.pyplot as plt\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0IpIWr57k9o"},"source":["# xv = re.sub(r'[\"?\"]+', \"?\", \"hghA AAg@hg??gh ff'ggf\".lower())\n","# xv = re.sub(r\"([?.!,])\", r\" \\1 \", xv)\n","# # xv\n","# re.sub(r\"[^a-z?.!,]+\", \" \", xv)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4rijmzdhtSWy"},"source":["# len = 0\n","# with open('/content/gdrive/My Drive/dialogs/reddit_big_comments/RC_2007-11', buffering=1000) as f_f:\n","#   for r in f_f:\n","#     len += 1\n","# len"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BlZMGiXY5T9x"},"source":["# bbb = 'please anwser my question'.split(' ')\n","# len(bbb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4FNt08nfdX5O"},"source":["Формируем файл с отфильтрованными комментариями"]},{"cell_type":"code","metadata":{"id":"Sg3yozQNlHzg"},"source":["# !ls \"/content/gdrive/My Drive/dialogs/reddit_big_comments\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWok8CKulUQv"},"source":["# # перобразовать с сохранением исходного\n","# !bzip2 --keep --decompress \"/content/gdrive/My Drive/dialogs/reddit_big_comments/RC_2008-03.bz2\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aioMNgbRqFMv"},"source":["# !rm \"/content/gdrive/My Drive/dialogs/reddit_big_comments/RC_2008-03\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6vLOXuTV1IOF"},"source":["# row_counter = -1\n","# num_file = 0\n","# year = 2008\n","# month = 3\n","# arr = []\n","# z =0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jGG2ww0N2j4s","executionInfo":{"status":"ok","timestamp":1598642314515,"user_tz":-180,"elapsed":55738,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"13a48a14-9671-4e78-eb71-5e3b6a03aeef","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# !bzip2 --keep --decompress \"/content/gdrive/My Drive/dialogs/reddit_big_comments/RC_2008-03.bz2\"\n","\n","# arr_transf = []\n","# def get_par(arr):\n","#   questions = []\n","#   answers = []\n","\n","# if year == 2009:\n","#   print(str(z)+' --- '+str(row_counter))\n","#   with open('/content/gdrive/My Drive/dialogs/reddit_big_comments/db/data_'+str(num_file)+'.json', 'w') as fw:\n","#     json.dump(arr, fw)\n","#     # json.dump(arr, fw, ensure_ascii=False)\n","#   print('End')\n","# else:\n","#   if month < 10:\n","#     str_month = '0'+str(month)\n","#   else:\n","#     str_month = str(month)\n","#   print('RC_'+str(year)+'-'+str_month)\n","#   with open('/content/gdrive/My Drive/dialogs/reddit_big_comments/RC_'+str(year)+'-'+str_month, buffering=1000) as f:\n","#     for row in f:\n","#       row_counter += 1\n","#       row = json.loads(row)\n","#       comment_id = row['name']\n","#       parent_id = row['parent_id']\n","#       body = x_preprocess_sentence(row['body'])\n","#       score = row['score']\n","#       if len(body) > 1 and len(body.split(' ')) < 20 and score > 9:\n","#         arr.append([comment_id, parent_id, body, score])\n","#         z += 1\n","#       if year < 2017 and z == 100000:\n","#         print(str(num_file)+'*1X --- '+str(row_counter))\n","#         arr_transf = arr\n","#         # get_par(arr)\n","#         with open('/content/gdrive/My Drive/dialogs/reddit_big_comments/db/data_'+str(num_file)+'.json', 'w') as fw:\n","#           json.dump(arr, fw)\n","#         z = 0\n","#         arr = []\n","#         num_file += 1\n","#       if year >= 2017 and z == 200000:\n","#         print(str(num_file)+'*2X --- '+str(row_counter))\n","#         with open('/content/gdrive/My Drive/dialogs/reddit_big_comments/db/data_'+str(num_file)+'.json', 'w') as fw:\n","#           json.dump(arr, fw)\n","#         z = 0\n","#         arr = []\n","#         num_file += 1\n","#   month += 1\n","#   if month > 12:\n","#     month = 1\n","#     year += 1\n","\n","# !rm \"/content/gdrive/My Drive/dialogs/reddit_big_comments/RC_2008-03\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["RC_2008-03\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"czSE6cpnTUPJ"},"source":["# questions = []\n","# answers = []\n","# zxs = 0\n","# child_arr_transf = arr_transf[:]\n","# for row_parent in arr_transf:\n","#   # print(row_parent)\n","#   body_child = ''\n","#   score_child = 0\n","#   arr_num_child = []\n","#   row_child_counter = 0\n","#   for row_child in child_arr_transf:\n","#     if row_parent[0] == row_child[1]:\n","#       if row_child_counter != 0: arr_num_child.append(row_child_counter)\n","#       if len(arr_num_child) == 0:\n","#         body_child = row_child[2]\n","#         score_child = row_child[3]\n","#       else:\n","#         if row_child[3] > score_child:\n","#           body_child = row_child[2]\n","#           score_child = row_child[3]\n","#     row_child_counter += 1\n","#   if len(arr_num_child) != 0:\n","#     questions.append(row_parent[2])\n","#     answers.append(body_child)\n","#     # print('question --- '+row_parent[2] )\n","#     # print('answer --- '+str(score_child)+'  ---'+body_child )\n","#     # print(arr_num_child)\n","#     # print(' -------------------- ')\n","#     # print(arr_num_child)\n","#   num_del = len(arr_num_child) - 1\n","#   for ifg in range(len(arr_num_child)):\n","#     # print(len(child_arr_transf))\n","#     del child_arr_transf[arr_num_child[num_del]]\n","#     num_del -= 1\n","#   if len(child_arr_transf) != 0: del child_arr_transf[0]\n","\n","#   zxs += 1\n","#   # if zxs == 1000: break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JXSSUp7i6wo8"},"source":["# pd.read_json( '/content/gdrive/My Drive/dialogs/reddit_big_comments/db/data_0.json' )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JUbHPCWheAOJ"},"source":["читаем отфильтрованный файл в оперативную память"]},{"cell_type":"code","metadata":{"id":"oZPkIF95ktou"},"source":["# with open('/content/gdrive/My Drive/dialogs/reddit_big_comments/db/train.from', buffering=1000) as f:\n","#   for row in f:\n","#     print(row)\n","#     print('-------------------------------')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYK8BulTlaSr"},"source":["# with open('/content/gdrive/My Drive/dialogs/reddit_big_comments/db/train.to', buffering=1000) as f:\n","#   for row in f:\n","#     print(row)\n","#     print('-------------------------------')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y0AqALdZCbCW"},"source":["##Prepare Dataset"]},{"cell_type":"code","metadata":{"id":"4AP3yF8suBbo"},"source":["# train_labels = pd.read_csv('/content/gdrive/My Drive/dialogs/twiter companies/4133_8841_bundle_archive/twcs/twcs.csv')\n","#                     # header=0, \n","#                     # names=['vacancy_id', 'specializations'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HmZKpn5Ju9Hz"},"source":["# train_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Anys1es5vYh2"},"source":["# train_labels = pd.read_csv('/content/gdrive/My Drive/dialogs/ubuntu/1982_3401_bundle_archive/Ubuntu-dialogue-corpus/dialogueText.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AL2TzzVFxgR4"},"source":["# train_labels[:50]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0u7-4MUBv26c"},"source":["# train_labels['text'][2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cII6NvUO6Qll"},"source":["# with open('/content/gdrive/My Drive/dialogs/reddit_sentdex/train.from', 'r') as f:\n","#     ques = f.read().splitlines()\n","\n","# with open('/content/gdrive/My Drive/dialogs/reddit_sentdex/train.to', 'r') as f:\n","#     answ = f.read().splitlines()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rhlICNCF9PH0"},"source":["# len(ques)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IvXKjX5v9VQ_"},"source":["# len(answ)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qnbdPyVQ9Z7c"},"source":["# ques[:50]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CuRzfejC9dzH"},"source":["# answ[:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CG0ZDK1UcDld","executionInfo":{"status":"ok","timestamp":1602134437587,"user_tz":-180,"elapsed":628,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["\n","def x_preprocess_sentence(sentence):\n","  sentence = sentence.lower()\n","  sentence = sentence.replace(\"’\", \"'\").replace(\"`\", \"'\")\n","  sentence = re.sub(r'[\".\"]+', \".\", sentence)\n","  sentence = re.sub(r'[\",\"]+', \",\", sentence)\n","  sentence = re.sub(r'[\"!\"]+', \"!\", sentence)\n","  sentence = re.sub(r'[\"?\"]+', \"?\", sentence)\n","  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","\n","  sentence = sentence.replace(\"i'm\", \"i am\")\n","  sentence = sentence.replace(\"you're\", \"you are\")\n","  sentence = sentence.replace(\"he's\", \"he is\")\n","  sentence = sentence.replace(\"she's\", \"she is\")\n","  sentence = sentence.replace(\"they're\", \"they are\")\n","  sentence = sentence.replace(\"we're\", \"we are\")\n","  sentence = sentence.replace(\"it's\", \"it is\")\n","  sentence = sentence.replace(\"that's\", \"that is\")\n","  sentence = sentence.replace(\"here's\", \"here is\")\n","  sentence = sentence.replace(\"i'll\", \"i will\")\n","  sentence = sentence.replace(\"you’ll\", \"you will\")\n","  sentence = sentence.replace(\"he'll\", \"he will\")\n","  sentence = sentence.replace(\"she'll\", \"she will\")\n","  sentence = sentence.replace(\"it'll\", \"it will\")\n","  sentence = sentence.replace(\"we'll\", \"we will\")\n","  sentence = sentence.replace(\"haven't\", \"have not\")\n","  sentence = sentence.replace(\"i've\", \"i have\")\n","  sentence = sentence.replace(\"you've\", \"you have\")\n","  sentence = sentence.replace(\"he's\", \"he has\")\n","  sentence = sentence.replace(\"she's\", \"she has\")\n","  sentence = sentence.replace(\"we've\", \"we have\")\n","  sentence = sentence.replace(\"they've\", \"they have\")\n","  sentence = sentence.replace(\"should've\", \"should have\")\n","  sentence = sentence.replace(\"could've\", \"could have\")\n","  sentence = sentence.replace(\"i'd\", \"i would\")\n","  sentence = sentence.replace(\"you'd\", \"you would\")\n","  sentence = sentence.replace(\"he'd\", \"he would\")\n","  sentence = sentence.replace(\"she'd\", \"she would\")\n","  sentence = sentence.replace(\"we'd\", \"we would\")\n","  sentence = sentence.replace(\"they'd\", \"they would\")\n","  sentence = sentence.replace(\"don't\", \"do not\")\n","  sentence = sentence.replace(\"can't\", \"can not\")\n","  sentence = sentence.replace(\"aren't\", \"are not\")\n","  sentence = sentence.replace(\"couldn't\", \"could not\")\n","  sentence = sentence.replace(\"wouldn't\", \"would not\")\n","  sentence = sentence.replace(\"shouldn't\", \"should not\")\n","  sentence = sentence.replace(\"isn't\", \"is not\")\n","  sentence = sentence.replace(\"doesn't\", \"does not\")\n","  sentence = sentence.replace(\"didn't\", \"did not\")\n","  sentence = sentence.replace(\"hasn't\", \"has not\")\n","  sentence = sentence.replace(\"wasn't\", \"was not\")\n","  sentence = sentence.replace(\"won't\", \"will not\")\n","  sentence = sentence.replace(\"weren't\", \"were not\")\n","  sentence = sentence.replace(\"let's\", \"let us\")\n","  sentence = sentence.replace(\"y'all\", \"you all\")\n","\n","  sentence = re.sub(r\"[^a-z?.!,]+\", \" \", sentence)\n","  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n","  sentence = sentence.strip()\n","  return sentence"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"p2iQD-9Q63oF"},"source":["# def x_preprocess_sentence(sentence):\n","#   sentence = sentence.lower().strip()\n","#   # creating a space between a word and the punctuation following it\n","#   # eg: \"he is a boy.\" => \"he is a boy .\"\n","#   sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","#   sentence = re.sub(r'[\" \"]+', \" \", sentence)\n","#   sentence = re.sub(r'[\".\"]+', \".\", sentence)\n","#   sentence = re.sub(r'[\"!\"]+', \"!\", sentence)\n","#   sentence = re.sub(r'[\"?\"]+', \"?\", sentence)\n","#   # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","#   sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n","#   sentence = sentence.strip()\n","#   # adding a start and an end token to the sentence\n","#   if sentence == 'deleted': sentence = ''\n","#   return sentence\n","\n","# # def x_clear_and_format_strings(arr_strings):\n","# #   arr_strings_new = []\n","# #   # z=0\n","# #   for string in arr_strings:\n","# #     # z=z+1\n","# #     # if str(z)[-3:] == '000':\n","# #     #   print(z)\n","# #     # string = string.replace('Ё', 'е').replace('ё', 'е')\n","# #     # string = re.sub(r\"[^a-zA-Zа-яА-Я0-9]+\", \" \", string)\n","# #     # string = re.sub(r'[\" \"]+', \" \", string)\n","# #     # string = string.lower().strip()\n","# #     # arr_words_new = []\n","# #     # arr_words = string.split(' ')\n","# #     # for word in arr_words:\n","# #     #   # word = stemer.stem(word)\n","# #     #   arr_words_new.append( word )\n","# #     # string = ' '.join(arr_words_new)\n","# #     string = x_preprocess_sentence(string)\n","# #     arr_strings_new.append( string )\n","# #   return arr_strings_new"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hoZJPlHd-bI4"},"source":["# x_clear_and_format_strings(ques[:5])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"an8WfZu2_M3Z"},"source":["# ques = x_clear_and_format_strings(ques)\n","# answ = x_clear_and_format_strings(answ)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c0LzKO_0_sE7"},"source":["# ques[:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LqNG4ed7_xzK"},"source":["# answ[:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_B147qKb_0ks"},"source":["# # Maximum number of samples to preprocess\n","# # MAX_SAMPLES = 50000\n","# MAX_SAMPLES = 221610\n","\n","# def preprocess_sentence(sentence):\n","#   sentence = sentence.lower().strip()\n","#   # creating a space between a word and the punctuation following it\n","#   # eg: \"he is a boy.\" => \"he is a boy .\"\n","#   sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","#   sentence = re.sub(r'[\" \"]+', \" \", sentence)\n","#   sentence = re.sub(r'[\".\"]+', \".\", sentence)\n","#   # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","#   sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n","#   sentence = sentence.strip()\n","#   # adding a start and an end token to the sentence\n","#   return sentence\n","\n","MAX_SAMPLES = 9999999999\n","\n","# path_to_zip = tf.keras.utils.get_file(\n","#     'cornell_movie_dialogs.zip',\n","#     origin=\n","#     'http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n","#     extract=True)\n","\n","# path_to_dataset = os.path.join(\n","#     os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\n","\n","path_to_movie_lines = '/content/gdrive/My Drive/dialogs/cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_lines.txt'\n","# path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n","path_to_movie_conversations = '/content/gdrive/My Drive/dialogs/cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_conversations.txt'\n","# path_to_movie_conversations = os.path.join(path_to_dataset,\n","#                                            'movie_conversations.txt')\n","\n","def load_conversations():\n","  # dictionary of line id to text\n","  id2line = {}\n","  with open(path_to_movie_lines, errors='ignore') as file:\n","    lines = file.readlines()\n","  for line in lines:\n","    parts = line.replace('\\n', '').split(' +++$+++ ')\n","    id2line[parts[0]] = parts[4]\n","\n","  inputs, outputs = [], []\n","  with open(path_to_movie_conversations, 'r') as file:\n","    lines = file.readlines()\n","  for line in lines:\n","    parts = line.replace('\\n', '').split(' +++$+++ ')\n","    # get conversation in a list of line ID\n","    conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n","    for i in range(len(conversation) - 1):\n","      inputs.append(x_preprocess_sentence(id2line[conversation[i]]))\n","      outputs.append(x_preprocess_sentence(id2line[conversation[i + 1]]))\n","      if len(inputs) >= MAX_SAMPLES:\n","        return inputs, outputs\n","  return inputs, outputs\n","\n","\n","questions_films, answers_films = load_conversations()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9rK1a4FYiHXx","executionInfo":{"status":"ok","timestamp":1600760841860,"user_tz":-180,"elapsed":9490,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"7efcbc98-9a75-4645-e893-9f79700e79f9","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["questions_films[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['can we make this quick ? roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad . again .',\n"," 'well , i thought we would start with pronunciation , if that is okay with you .',\n"," 'not the hacking and gagging and spitting part . please .',\n"," 'you are asking me out . that is so cute . what s your name again ?',\n"," 'no , no , it is my fault we did not have a proper introduction']"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"G7bYgmYKiLLr","executionInfo":{"status":"ok","timestamp":1600760841861,"user_tz":-180,"elapsed":6800,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"cf03e214-bb28-4d2b-c506-731e2ce03e41","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["answers_films[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['well , i thought we would start with pronunciation , if that is okay with you .',\n"," 'not the hacking and gagging and spitting part . please .',\n"," 'okay . then how bout we try out some french cuisine . saturday ? night ?',\n"," 'forget it .',\n"," 'cameron .']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"ZaJVzplOpenl","executionInfo":{"status":"ok","timestamp":1600760841861,"user_tz":-180,"elapsed":2817,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"0a075ef1-acf2-477d-b6f7-f5d282f7ecaa","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(questions_films)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["221616"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"TmLgeejB869u"},"source":["# questions = questions + ques\n","# answers = answers + answ\n","# questions = ques\n","# answers = answ"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c0TXChtibp9B"},"source":["from reddit big comments"]},{"cell_type":"code","metadata":{"id":"NKRBAKZrbpUT"},"source":["questions = []\n","answers = []\n","for ar_n in range(2):\n","  # print(ar_n)\n","  with open('/content/gdrive/My Drive/dialogs/reddit_big_comments/questions_answers_12/'+str(ar_n)+'/questions.json', 'r') as f:\n","      questions = questions + json.load(f)\n","  with open('/content/gdrive/My Drive/dialogs/reddit_big_comments/questions_answers_12/'+str(ar_n)+'/answers.json', 'r') as f:\n","      answers = answers + json.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"elfMbzIl9Jyg","executionInfo":{"status":"ok","timestamp":1602092327028,"user_tz":-180,"elapsed":649,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"ff319821-ceef-467f-aecc-c92e185777ef","colab":{"base_uri":"https://localhost:8080/"}},"source":["len(questions)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3491821"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"6k7thWPH9Luq","executionInfo":{"status":"ok","timestamp":1600760853051,"user_tz":-180,"elapsed":745,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"9d895c11-b6b5-4c18-98b5-45d1c7c1d081","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(answers)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3491821"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"Kl1cYHGbx7cx"},"source":["# t_l = pd.read_csv('/content/gdrive/My Drive/dialogs/ubuntu/1982_3401_bundle_archive/Ubuntu-dialogue-corpus/dialogueText_301.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qrLpL9Pdy1le"},"source":["# t_l[500:550]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zYKzCyz2dyuX"},"source":["# Урок №1 19:35\n","# Урок №3 17:58\n","vocab_first_words = [\n","    'will',\n","    'do',\n","    'does',\n","    'did',\n","    'am',\n","    'is',\n","    'are',\n","    'was',\n","    'were',\n","    'would'\n","    'can',\n","    'could',\n","    'what',\n","    'which',\n","    'where',\n","    'when',\n","    'who',\n","    'why',\n","    'how',\n","    'whose',\n","    'whom',\n","    'it',\n","    'i',\n","    'you',\n","    'we',\n","    'they',\n","    'he',\n","    'she'\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yRRoSJtMI5m_"},"source":["questions_film_comments = questions_films + questions\n","answers_film_comments = answers_films + answers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i1Rwjc-XudK9"},"source":["qestions_without = []\n","answers_without = []\n","for n in range(len(questions)):\n","  q_w = re.sub(r\"[^a-z]+\", \" \", questions[n])\n","  q_w = re.sub(r'[\" \"]+', \" \", q_w)\n","  q_w = q_w.strip()\n","  first_word = q_w.split(' ')[0]\n","  if first_word in vocab_first_words:\n","    qestions_without.append(q_w)\n","    answers_without.append(answers[n])\n","  # if len(q_w.split(' ')) > 1:\n","  #   qestions_without.append(q_w)\n","# print(qestions_without)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwyj8S9yfflI","executionInfo":{"status":"ok","timestamp":1602092856992,"user_tz":-180,"elapsed":585,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"a31a3d03-9af8-4856-e3c4-8dc4d9fedfa4","colab":{"base_uri":"https://localhost:8080/"}},"source":["len(qestions_without)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["910202"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"BcGmWB79LWFk","executionInfo":{"status":"ok","timestamp":1602092914574,"user_tz":-180,"elapsed":410,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"88f8bd58-5d25-446d-88c6-2a71a913080c","colab":{"base_uri":"https://localhost:8080/"}},"source":["len(answers_without)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["910202"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"wqCiGjPXuoAV","executionInfo":{"status":"ok","timestamp":1602092922124,"user_tz":-180,"elapsed":737,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"c8ecd3fb-6b88-47ed-faa6-afb2ce4e713e","colab":{"base_uri":"https://localhost:8080/"}},"source":["qestions_without[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['it is chris hansen',\n"," 'how exactly can a refrigerator kill an elephant',\n"," 'you cant rape yourself',\n"," 'i was afraid that was going to be a rickroll',\n"," 'they are gonna sling it on ebay for crack money',\n"," 'i am dying to know where this photo was taken',\n"," 'i am bill clinton and i approve of this message',\n"," 'i think a burrito is still more valuable than oklahoma',\n"," 'i tuned your car s antenna off',\n"," 'i was blissfully in the dark']"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"c6XXGvOZLl66","executionInfo":{"status":"ok","timestamp":1602092956526,"user_tz":-180,"elapsed":668,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"1adcea65-663f-4653-8b0e-97b380a76f8c","colab":{"base_uri":"https://localhost:8080/"}},"source":["answers_without[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['why do not you have a seat .',\n"," 'a very , very big refrigerator .',\n"," 'unless you are underage and record it .',\n"," 'you may have ptsd .',\n"," 'crack money ? that is optimistic . my bet s twinkies .',\n"," 'larry craig s office .',\n"," 'you mean . massage . ?',\n"," 'as a citizen of oklahoma , i agree .',\n"," 'nigga tuned my hubcaps',\n"," 'sorry']"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"Jvp2XKkqp97y"},"source":["def make_vocab_with_all_words(arr_strings):\n","  # arr_strings = clear_and_format_strings(arr_strings)\n","  obj_words_new = {}\n","  for string in arr_strings:\n","    # arr_words = string.split(' ')\n","    # for word in arr_words:\n","      # exist = word in obj_words_new\n","      # if exist:\n","      #   obj_words_new[word] = obj_words_new[word] + 1\n","      # else:\n","      #   obj_words_new[word] = 1\n","      exist = string in obj_words_new\n","      if exist:\n","        obj_words_new[string] = obj_words_new[string] + 1\n","      else:\n","        obj_words_new[string] = 1\n","  return sorted(obj_words_new.items(), key=lambda item: item[1], reverse=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T2R2io0kuyE2"},"source":["zzz = make_vocab_with_all_words(qestions_without)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HukOXSjhXvYy","executionInfo":{"status":"ok","timestamp":1602093072446,"user_tz":-180,"elapsed":596,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"5cddef81-22d5-45ec-c266-184ec4e78029","colab":{"base_uri":"https://localhost:8080/"}},"source":["len(zzz)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["794511"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"bNkhUYoyvTrM","executionInfo":{"status":"ok","timestamp":1602093085663,"user_tz":-180,"elapsed":781,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"51f06973-4bc9-4e8d-989b-2fb044337838","colab":{"base_uri":"https://localhost:8080/"}},"source":["zzz[:100]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('what', 2042),\n"," ('why', 1303),\n"," ('i do not get it', 851),\n"," ('who', 757),\n"," ('i love you', 717),\n"," ('it is known', 693),\n"," ('what the fuck', 671),\n"," ('why not both', 667),\n"," ('i see what you did there', 546),\n"," ('you are', 495),\n"," ('you are welcome', 389),\n"," ('i like you', 376),\n"," ('how', 375),\n"," ('what is this from', 353),\n"," ('it is', 317),\n"," ('does not matter had sex', 286),\n"," ('why not', 251),\n"," ('i am', 239),\n"," ('i do', 228),\n"," ('are you fucking sorry', 223),\n"," ('i agree', 215),\n"," ('i have the weirdest boner right now', 213),\n"," ('i want to believe', 210),\n"," ('you rang', 209),\n"," ('where', 202),\n"," ('you called', 200),\n"," ('which one', 198),\n"," ('where is this', 193),\n"," ('i came', 189),\n"," ('i am sorry', 185),\n"," ('you monster', 182),\n"," ('what game is this', 179),\n"," ('it is a trap', 175),\n"," ('i do not', 175),\n"," ('i hate you', 171),\n"," ('i will be in my bunk', 169),\n"," ('i know', 168),\n"," ('what is it', 167),\n"," ('what do you mean you people', 164),\n"," ('i can confirm this', 161),\n"," ('you i like you', 161),\n"," ('do it', 159),\n"," ('where is this from', 155),\n"," ('i second this', 154),\n"," ('you are not alone', 153),\n"," ('we did it reddit', 153),\n"," ('what did he say', 147),\n"," ('i will allow it', 144),\n"," ('what the fuck did i just watch', 143),\n"," ('i need an adult', 142),\n"," ('it went okay', 137),\n"," ('it belongs in a museum', 136),\n"," ('what the fuck did i just read', 135),\n"," ('what is this', 134),\n"," ('i concur', 133),\n"," ('what the actual fuck', 133),\n"," ('i did', 132),\n"," ('do you even lift', 131),\n"," ('i love lamp', 130),\n"," ('who does not', 130),\n"," ('why not zoidberg', 130),\n"," ('you win', 129),\n"," ('i like turtles', 129),\n"," ('is this real life', 129),\n"," ('did you see that ludicrous display last night', 129),\n"," ('who is this', 129),\n"," ('what s this from', 129),\n"," ('i dont get it', 128),\n"," ('it is not', 126),\n"," ('you', 125),\n"," ('i would hit it', 122),\n"," ('are you me', 119),\n"," ('what happened', 118),\n"," ('are you my mummy', 117),\n"," ('she', 117),\n"," ('it is not your fault', 117),\n"," ('how you doin', 117),\n"," ('you do not', 116),\n"," ('i do not know', 114),\n"," ('do not tell me what to do', 111),\n"," ('i like it', 111),\n"," ('he is', 111),\n"," ('will do', 110),\n"," ('are you a wizard', 110),\n"," ('she is', 109),\n"," ('you have been banned from r pyongyang', 108),\n"," ('i have made a huge mistake', 107),\n"," ('did he died', 107),\n"," ('they are', 107),\n"," ('what is that', 107),\n"," ('what a twist', 106),\n"," ('i do not believe you', 106),\n"," ('i am ron burgundy', 104),\n"," ('what does that even mean', 104),\n"," ('i love you too', 100),\n"," ('how old are you', 100),\n"," ('what is dead may never die', 100),\n"," ('i disagree', 98),\n"," ('you can not explain that', 98),\n"," ('i understood that reference', 98)]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"jcF0HctJd9aK"},"source":["# questions = questions + questions_films\n","# answers = answers + answers_films\n","# questions = questions_films\n","# answers = answers_films\n","questions = qestions_without\n","answers = answers_without\n","# questions = questions[:200000]\n","# answers = answers[:200000]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IlaTab9eeIRh","executionInfo":{"status":"ok","timestamp":1602093207516,"user_tz":-180,"elapsed":786,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"25ac57cd-7285-456a-8484-4e460eadfe94","colab":{"base_uri":"https://localhost:8080/"}},"source":["len(answers)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["910202"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"OcxI6V3ebCJr"},"source":["# questions_new = []\n","# answers_new = []\n","# for n in range(len(questions)):\n","#   if str(aaa)[-5:] == '00000': \n","#     print(n)\n","#     # break\n","#   if len(questions[n].split(' ')) <= 12 and len(answers[n].split(' ')) <= 12:\n","#     questions_new.append(questions[n])\n","#     answers_new.append(answers[n])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"27rzQN3TcbaC"},"source":["# len(questions_new)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oiacbdc5ceAy"},"source":["# len(answers_new)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nb5e_oG3b28C"},"source":["# questions = questions_new\n","# answers = answers_new"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ntv8_6xjdzV4"},"source":["# with open('/content/gdrive/My Drive/dialogs/reddit_big_comments/not_more_then_10_len/questions.json', 'w') as fw:\n","#   json.dump(questions, fw)\n","# with open('/content/gdrive/My Drive/dialogs/reddit_big_comments/not_more_then_10_len/answers.json', 'w') as fw:\n","#   json.dump(answers, fw)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"egRqe-fw8lBi"},"source":["# listone = ['1','2','3']\n","# listtwo = ['4','5','6']\n","\n","# mergedlist = listone + listtwo\n","# print(mergedlist)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mfOOK5f7Wm6c","executionInfo":{"status":"ok","timestamp":1602093214819,"user_tz":-180,"elapsed":418,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"788f6d9f-8ea6-4320-cd33-a91c1da766cb","colab":{"base_uri":"https://localhost:8080/"}},"source":["print('Sample question: {}'.format(questions[20]))\n","print('Sample answer: {}'.format(answers[20]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sample question: i think most cops deserve to be sodomized\n","Sample answer: with a x .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s6XX2udMTCQt"},"source":["# Build tokenizer using tfds for both questions and answers\n","tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n","    questions + answers, target_vocab_size=2**13)\n","\n","# Define start and end token to indicate the start and end of a sentence\n","START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n","\n","# Vocabulary size plus start and end token\n","VOCAB_SIZE = tokenizer.vocab_size + 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LUXkfroSpwJE"},"source":["# save\n","tokenizer.save_to_file('/content/gdrive/My Drive/dialogs/reddit_big_comments/questions_answers_12/tokenizer')\n","# Load\n","# tokenizer = tfds.features.text.SubwordTextEncoder.load_from_file('/content/gdrive/My Drive/dialogs/reddit_big_comments/questions_answers_12/tokenizer')\n","\n","# Define start and end token to indicate the start and end of a sentence\n","# START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n","\n","# Vocabulary size plus start and end token\n","# VOCAB_SIZE = tokenizer.vocab_size + 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pIuU6D1iAMHp","executionInfo":{"status":"ok","timestamp":1602093901378,"user_tz":-180,"elapsed":716,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"1f3288a7-a4b6-4ddb-a57e-64bb41c91bec","colab":{"base_uri":"https://localhost:8080/"}},"source":["print('Tokenized sample question: {}'.format(tokenizer.encode(questions[20])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tokenized sample question: [1, 43, 253, 7144, 2601, 10, 36, 254, 1906, 2885, 8013]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h5h8pvRUTFt5","executionInfo":{"status":"ok","timestamp":1602093904253,"user_tz":-180,"elapsed":689,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"7cbb6c0d-dfd8-4212-bcee-b64547865353","colab":{"base_uri":"https://localhost:8080/"}},"source":["print('Tokenized sample question: {}'.format(tokenizer.encode(questions[20])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tokenized sample question: [1, 43, 253, 7144, 2601, 10, 36, 254, 1906, 2885, 8013]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c1Od_preWllV","executionInfo":{"status":"ok","timestamp":1600618451252,"user_tz":-180,"elapsed":774,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"b18b0eb4-204d-48c6-f1f9-00272ae7e420","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tokenizer"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<SubwordTextEncoder vocab_size=8180>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"YESTPgeg_XgT"},"source":["# Maximum sentence length\n","MAX_LENGTH = 14\n","# MAX_LENGTH = 30\n","# MAX_LENGTH = 40\n","\n","\n","# Tokenize, filter and pad sentences\n","def tokenize_and_filter(inputs, outputs):\n","  tokenized_inputs, tokenized_outputs = [], []\n","  \n","  for (sentence1, sentence2) in zip(inputs, outputs):\n","    # tokenize sentence\n","    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n","    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n","    # check tokenized sentence max length\n","    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n","      tokenized_inputs.append(sentence1)\n","      tokenized_outputs.append(sentence2)\n","  \n","  # pad tokenized sentences\n","  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n","      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n","  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n","      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n","  \n","  return tokenized_inputs, tokenized_outputs\n","\n","\n","# questions, answers = tokenize_and_filter(questions, answers)\n","q, a = tokenize_and_filter(questions, answers)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YI3MnJnzMGJQ"},"source":["questions = q\n","answers = a\n","# questions = q[:10000000]\n","# answers = a[:10000000]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P9taEY8jIbmk","executionInfo":{"status":"ok","timestamp":1602093989652,"user_tz":-180,"elapsed":687,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"d36cc0e5-4f42-4447-a7ec-67493a1b745e","colab":{"base_uri":"https://localhost:8080/"}},"source":["len(questions)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["723191"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"pohHm8IRWlIH","executionInfo":{"status":"ok","timestamp":1602094001214,"user_tz":-180,"elapsed":754,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"2009b205-e089-4706-cddb-89e12af1213e","colab":{"base_uri":"https://localhost:8080/"}},"source":["print('Vocab size: {}'.format(VOCAB_SIZE))\n","print('Number of samples: {}'.format(len(q)))\n","# print('Number of samples: {}'.format(len(questions)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Vocab size: 8171\n","Number of samples: 723191\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S50jT4upWh5c"},"source":["### Create `tf.data.Dataset`\n","\n","We are going to use the [tf.data.Dataset API](https://www.tensorflow.org/api_docs/python/tf/data) to contruct our input pipline in order to utilize features like caching and prefetching to speed up the training process.\n","\n","The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next.\n","\n","During training this example uses teacher-forcing. Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n","\n","As the transformer predicts each word, self-attention allows it to look at the previous words in the input sequence to better predict the next word.\n","\n","To prevent the model from peaking at the expected output the model uses a look-ahead mask.\n","\n","Target is divided into `decoder_inputs` which padded as an input to the decoder and `cropped_targets` for calculating our loss and accuracy."]},{"cell_type":"code","metadata":{"id":"pttC3XxgAXWQ"},"source":["BATCH_SIZE = 128*4\n","# BATCH_SIZE = 128\n","BUFFER_SIZE = 20000\n","\n","# decoder inputs use the previous target as input\n","# remove START_TOKEN from targets\n","dataset = tf.data.Dataset.from_tensor_slices((\n","    {\n","        'inputs': questions,\n","        'dec_inputs': answers[:, :-1]\n","    },\n","    {\n","        'outputs': answers[:, 1:]\n","    },\n","))\n","\n","dataset = dataset.cache()\n","dataset = dataset.shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE)\n","dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mU8yNWpwPlS7","executionInfo":{"status":"ok","timestamp":1602094026075,"user_tz":-180,"elapsed":692,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"45e350c6-2db1-4d26-cd24-96a95a42c5ad","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<PrefetchDataset shapes: ({inputs: (None, 14), dec_inputs: (None, 13)}, {outputs: (None, 13)}), types: ({inputs: tf.int32, dec_inputs: tf.int32}, {outputs: tf.int32})>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s9eeMPjGXmI1"},"source":["## Attention\n","\n"]},{"cell_type":"markdown","metadata":{"id":"uctkwvPZVSzu"},"source":["### Scaled dot product Attention\n","\n","The scaled dot-product attention function used by the transformer takes three inputs: Q (query), K (key), V (value). The equation used to calculate the attention weights is:\n","\n","$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n","\n","As the softmax normalization is done on the `key`, its values decide the amount of importance given to the `query`.\n","\n","The output represents the multiplication of the attention weights and the `value` vector. This ensures that the words we want to focus on are kept as is and the irrelevant words are flushed out.\n","\n","The dot-product attention is scaled by a factor of square root of the depth. This is done because for large values of depth, the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax. \n","\n","For example, consider that `query` and `key` have a mean of 0 and variance of 1. Their matrix multiplication will have a mean of 0 and variance of `dk`. Hence, *square root of `dk`* is used for scaling (and not any other number) because the matmul of `query` and `key` should have a mean of 0 and variance of 1, so that we get a gentler softmax.\n","\n","The mask is multiplied with *-1e9 (close to negative infinity).* This is done because the mask is summed with the scaled matrix multiplication of `query` and `key` and is applied immediately before a softmax. The goal is to zero out these cells, and large negative inputs to softmax are near zero in the output."]},{"cell_type":"code","metadata":{"id":"ENfqAFna_50H","executionInfo":{"status":"ok","timestamp":1602134482890,"user_tz":-180,"elapsed":681,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["def scaled_dot_product_attention(query, key, value, mask):\n","  \"\"\"Calculate the attention weights. \"\"\"\n","  matmul_qk = tf.matmul(query, key, transpose_b=True)\n","\n","  # scale matmul_qk\n","  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n","  logits = matmul_qk / tf.math.sqrt(depth)\n","\n","  # add the mask to zero out padding tokens\n","  if mask is not None:\n","    logits += (mask * -1e9)\n","\n","  # softmax is normalized on the last axis (seq_len_k)\n","  attention_weights = tf.nn.softmax(logits, axis=-1)\n","\n","  output = tf.matmul(attention_weights, value)\n","\n","  return output"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XwmOB9HvVbyh"},"source":["### Multi-head attention\n","\n","<img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">\n","\n","\n","Multi-head attention consists of four parts:\n","* Linear layers and split into heads.\n","* Scaled dot-product attention.\n","* Concatenation of heads.\n","* Final linear layer.\n","\n","Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads. \n","\n","The `scaled_dot_product_attention` defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step.  The attention output for each head is then concatenated (using `tf.transpose`, and `tf.reshape`) and put through a final `Dense` layer.\n","\n","Instead of one single attention head, `query`, `key`, and `value` are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality."]},{"cell_type":"code","metadata":{"id":"L9eYssGIAG4h","executionInfo":{"status":"ok","timestamp":1602134486311,"user_tz":-180,"elapsed":566,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","\n","  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n","    super(MultiHeadAttention, self).__init__(name=name)\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","\n","    assert d_model % self.num_heads == 0\n","\n","    self.depth = d_model // self.num_heads\n","\n","    self.query_dense = tf.keras.layers.Dense(units=d_model)\n","    self.key_dense = tf.keras.layers.Dense(units=d_model)\n","    self.value_dense = tf.keras.layers.Dense(units=d_model)\n","\n","    self.dense = tf.keras.layers.Dense(units=d_model)\n","\n","  def split_heads(self, inputs, batch_size):\n","    inputs = tf.reshape(\n","        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n","\n","  def call(self, inputs):\n","    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n","        'value'], inputs['mask']\n","    batch_size = tf.shape(query)[0]\n","\n","    # linear layers\n","    query = self.query_dense(query)\n","    key = self.key_dense(key)\n","    value = self.value_dense(value)\n","\n","    # split heads\n","    query = self.split_heads(query, batch_size)\n","    key = self.split_heads(key, batch_size)\n","    value = self.split_heads(value, batch_size)\n","\n","    # scaled dot-product attention\n","    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n","\n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","    # concatenation of heads\n","    concat_attention = tf.reshape(scaled_attention,\n","                                  (batch_size, -1, self.d_model))\n","\n","    # final linear layer\n","    outputs = self.dense(concat_attention)\n","\n","    return outputs"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eDUX7Oa8Xudj"},"source":["## Transformer"]},{"cell_type":"markdown","metadata":{"id":"x5QlgXsxYirg"},"source":["### Masking\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0CX5H8A-Wybj"},"source":["`create_padding_mask` and `create_look_ahead` are helper functions to creating masks to mask out padded tokens, we are going to use these helper functions as `tf.keras.layers.Lambda` layers.\n","\n","Mask all the pad tokens (value `0`) in the batch to ensure the model does not treat padding as input."]},{"cell_type":"code","metadata":{"id":"imCQ0jrvWhC7","executionInfo":{"status":"ok","timestamp":1602134490319,"user_tz":-180,"elapsed":550,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["def create_padding_mask(x):\n","  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n","  # (batch_size, 1, 1, sequence length)\n","  return mask[:, tf.newaxis, tf.newaxis, :]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"IrwtsqrfWd-3","executionInfo":{"status":"ok","timestamp":1602094794320,"user_tz":-180,"elapsed":880,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"65f571c6-1177-449b-f970-bb5ba65b345a","colab":{"base_uri":"https://localhost:8080/"}},"source":["create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2, 1, 1, 5), dtype=float32, numpy=\n","array([[[[0., 0., 1., 0., 1.]]],\n","\n","\n","       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"markdown","metadata":{"id":"qJAicy1zW1QT"},"source":["Look-ahead mask to mask the future tokens in a sequence.\n","We also mask out pad tokens.\n","\n","i.e. To predict the third word, only the first and second word will be used"]},{"cell_type":"code","metadata":{"id":"HSVdD2zKWaXx","executionInfo":{"status":"ok","timestamp":1602134493120,"user_tz":-180,"elapsed":551,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["def create_look_ahead_mask(x):\n","  seq_len = tf.shape(x)[1]\n","  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n","  padding_mask = create_padding_mask(x)\n","  return tf.maximum(look_ahead_mask, padding_mask)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"xhwz9xzxWcod","executionInfo":{"status":"ok","timestamp":1602094799528,"user_tz":-180,"elapsed":644,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"5900be4f-32d6-400b-941c-ef118204a382","colab":{"base_uri":"https://localhost:8080/"}},"source":["create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=\n","array([[[[0., 1., 1., 1., 1.],\n","         [0., 0., 1., 1., 1.],\n","         [0., 0., 1., 1., 1.],\n","         [0., 0., 1., 0., 1.],\n","         [0., 0., 1., 0., 0.]]]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"markdown","metadata":{"id":"TpR7kz4jFkPJ"},"source":["### Positional encoding\n","\n","Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence. \n","\n","The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space.\n","\n","See the notebook on [positional encoding](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) to learn more about it. The formula for calculating the positional encoding is as follows:\n","\n","$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n","$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"]},{"cell_type":"code","metadata":{"id":"-9Oibz2es-qW","executionInfo":{"status":"ok","timestamp":1602134495722,"user_tz":-180,"elapsed":577,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["class PositionalEncoding(tf.keras.layers.Layer):\n","\n","  def __init__(self, position, d_model):\n","    super(PositionalEncoding, self).__init__()\n","    self.pos_encoding = self.positional_encoding(position, d_model)\n","\n","  def get_angles(self, position, i, d_model):\n","    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n","    return position * angles\n","\n","  def positional_encoding(self, position, d_model):\n","    angle_rads = self.get_angles(\n","        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n","        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n","        d_model=d_model)\n","    # apply sin to even index in the array\n","    sines = tf.math.sin(angle_rads[:, 0::2])\n","    # apply cos to odd index in the array\n","    cosines = tf.math.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = tf.concat([sines, cosines], axis=-1)\n","    pos_encoding = pos_encoding[tf.newaxis, ...]\n","    return tf.cast(pos_encoding, tf.float32)\n","\n","  def call(self, inputs):\n","    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"UC_fQehi3_Yh","executionInfo":{"status":"ok","timestamp":1602134500111,"user_tz":-180,"elapsed":838,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["sample_pos_encoding = PositionalEncoding(50, 512)\n","\n","# plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n","# plt.xlabel('Depth')\n","# plt.xlim((0, 512))\n","# plt.ylabel('Position')\n","# plt.colorbar()\n","# plt.show()"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HVazCemoW2Ye"},"source":["### Encoder Layer\n","\n","Each encoder layer consists of sublayers:\n","\n","1. Multi-head attention (with padding mask) \n","2. 2 dense layers followed by dropout\n","\n","Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n","\n","The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis."]},{"cell_type":"code","metadata":{"id":"5guJOLJmfcuX","executionInfo":{"status":"ok","timestamp":1602134502566,"user_tz":-180,"elapsed":566,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  attention = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention\")({\n","          'query': inputs,\n","          'key': inputs,\n","          'value': inputs,\n","          'mask': padding_mask\n","      })\n","  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n","  attention = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(inputs + attention)\n","\n","  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention + outputs)\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"K16BIGSKfkve","executionInfo":{"status":"ok","timestamp":1602134505280,"user_tz":-180,"elapsed":1176,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["sample_encoder_layer = encoder_layer(\n","    units=512,\n","    d_model=128,\n","    num_heads=4,\n","    dropout=0.3,\n","    name=\"sample_encoder_layer\")\n","\n","# tf.keras.utils.plot_model(\n","#     sample_encoder_layer, to_file='encoder_layer.png', show_shapes=True)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9r8lWGClfi_1"},"source":["### Encoder\n","\n","The Encoder consists of:\n","1.   Input Embedding\n","2.   Positional Encoding\n","3.   `num_layers` encoder layers\n","\n","The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."]},{"cell_type":"code","metadata":{"id":"LRfugon5Wy-Y","executionInfo":{"status":"ok","timestamp":1602134508323,"user_tz":-180,"elapsed":923,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["def encoder(vocab_size,\n","            num_layers,\n","            units,\n","            d_model,\n","            num_heads,\n","            dropout,\n","            name=\"encoder\"):\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n","\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  for i in range(num_layers):\n","    outputs = encoder_layer(\n","        units=units,\n","        d_model=d_model,\n","        num_heads=num_heads,\n","        dropout=dropout,\n","        name=\"encoder_layer_{}\".format(i),\n","    )([outputs, padding_mask])\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"bNxCnjrvglnx","executionInfo":{"status":"ok","timestamp":1602134511122,"user_tz":-180,"elapsed":1306,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["sample_encoder = encoder(\n","    vocab_size=8192,\n","    num_layers=2,\n","    units=512,\n","    d_model=128,\n","    num_heads=4,\n","    dropout=0.3,\n","    name=\"sample_encoder\")\n","\n","# tf.keras.utils.plot_model(\n","#    sample_encoder, to_file='encoder.png', show_shapes=True)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"af66azvgW9P-"},"source":["### Decoder Layer\n","\n","Each decoder layer consists of sublayers:\n","\n","1.   Masked multi-head attention (with look ahead mask and padding mask)\n","2.   Multi-head attention (with padding mask). `value` and `key` receive the *encoder output* as inputs. `query` receives the *output from the masked multi-head attention sublayer.*\n","3.   2 dense layers followed by dropout\n","\n","Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n","\n","As `query` receives the output from decoder's first attention block, and `key` receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."]},{"cell_type":"code","metadata":{"id":"6mLvvNMWgDnf","executionInfo":{"status":"ok","timestamp":1602134513587,"user_tz":-180,"elapsed":571,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n","  look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name=\"look_ahead_mask\")\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","  attention1 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_1\")(inputs={\n","          'query': inputs,\n","          'key': inputs,\n","          'value': inputs,\n","          'mask': look_ahead_mask\n","      })\n","  attention1 = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention1 + inputs)\n","\n","  attention2 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_2\")(inputs={\n","          'query': attention1,\n","          'key': enc_outputs,\n","          'value': enc_outputs,\n","          'mask': padding_mask\n","      })\n","  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n","  attention2 = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention2 + attention1)\n","\n","  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(outputs + attention2)\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"8M1NrQ_NgEaM","executionInfo":{"status":"ok","timestamp":1602134516521,"user_tz":-180,"elapsed":872,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["sample_decoder_layer = decoder_layer(\n","    units=512,\n","    d_model=128,\n","    num_heads=4,\n","    dropout=0.3,\n","    name=\"sample_decoder_layer\")\n","\n","# tf.keras.utils.plot_model(\n","#     sample_decoder_layer, to_file='decoder_layer.png', show_shapes=True)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NPSKnjS-gE_q"},"source":["### Decoder\n","\n","The Decoder consists of:\n","1.   Output Embedding\n","2.   Positional Encoding\n","3.   N decoder layers\n","\n","The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."]},{"cell_type":"code","metadata":{"id":"dYRx7YzCW4bu","executionInfo":{"status":"ok","timestamp":1602134518650,"user_tz":-180,"elapsed":610,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["def decoder(vocab_size,\n","            num_layers,\n","            units,\n","            d_model,\n","            num_heads,\n","            dropout,\n","            name='decoder'):\n","  inputs = tf.keras.Input(shape=(None,), name='inputs')\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n","  look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name='look_ahead_mask')\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","  \n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n","\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  for i in range(num_layers):\n","    outputs = decoder_layer(\n","        units=units,\n","        d_model=d_model,\n","        num_heads=num_heads,\n","        dropout=dropout,\n","        name='decoder_layer_{}'.format(i),\n","    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"tUdK8jb9hlTZ","executionInfo":{"status":"ok","timestamp":1602134521780,"user_tz":-180,"elapsed":1541,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["sample_decoder = decoder(\n","    vocab_size=8192,\n","    num_layers=2,\n","    units=512,\n","    d_model=128,\n","    num_heads=4,\n","    dropout=0.3,\n","    name=\"sample_decoder\")\n","\n","# tf.keras.utils.plot_model(\n","#     sample_decoder, to_file='decoder.png', show_shapes=True)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yl0o97RJXAqw"},"source":["### Transformer\n","\n","Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."]},{"cell_type":"code","metadata":{"id":"TW-v7Fz6XAfC","executionInfo":{"status":"ok","timestamp":1602134522743,"user_tz":-180,"elapsed":536,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["def transformer(vocab_size,\n","                num_layers,\n","                units,\n","                d_model,\n","                num_heads,\n","                dropout,\n","                name=\"transformer\"):\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n","\n","  enc_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='enc_padding_mask')(inputs)\n","  # mask the future tokens for decoder inputs at the 1st attention block\n","  look_ahead_mask = tf.keras.layers.Lambda(\n","      create_look_ahead_mask,\n","      output_shape=(1, None, None),\n","      name='look_ahead_mask')(dec_inputs)\n","  # mask the encoder outputs for the 2nd attention block\n","  dec_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='dec_padding_mask')(inputs)\n","\n","  enc_outputs = encoder(\n","      vocab_size=vocab_size,\n","      num_layers=num_layers,\n","      units=units,\n","      d_model=d_model,\n","      num_heads=num_heads,\n","      dropout=dropout,\n","  )(inputs=[inputs, enc_padding_mask])\n","\n","  dec_outputs = decoder(\n","      vocab_size=vocab_size,\n","      num_layers=num_layers,\n","      units=units,\n","      d_model=d_model,\n","      num_heads=num_heads,\n","      dropout=dropout,\n","  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n","\n","  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n","\n","  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"aihJLVq_iJ_T","executionInfo":{"status":"ok","timestamp":1602134530270,"user_tz":-180,"elapsed":5511,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["sample_transformer = transformer(\n","    vocab_size=8192,\n","    num_layers=4,\n","    units=512,\n","    d_model=128,\n","    num_heads=4,\n","    dropout=0.3,\n","    name=\"sample_transformer\")\n","\n","# tf.keras.utils.plot_model(\n","#     sample_transformer, to_file='transformer.png', show_shapes=True)"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9HD7GK-nh_KT"},"source":["## Train model"]},{"cell_type":"markdown","metadata":{"id":"PDDxNpA-5Q5t"},"source":["### Initialize model\n","\n","To keep this example small and relatively fast, the values for *num_layers, d_model, and units* have been reduced. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer."]},{"cell_type":"code","metadata":{"id":"xE3unrOT5M5z","executionInfo":{"status":"ok","timestamp":1602134530271,"user_tz":-180,"elapsed":3829,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["# # tf.keras.backend.clear_session()\n","\n","# # Hyper-parameters\n","NUM_LAYERS = 2\n","D_MODEL = 256\n","NUM_HEADS = 8\n","UNITS = 512\n","DROPOUT = 0.1\n","\n","# model = transformer(\n","#     vocab_size=VOCAB_SIZE,\n","#     num_layers=NUM_LAYERS,\n","#     units=UNITS,\n","#     d_model=D_MODEL,\n","#     num_heads=NUM_HEADS,\n","#     dropout=DROPOUT)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0_GCb0LaV1tI"},"source":["### Loss function\n","\n","Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."]},{"cell_type":"code","metadata":{"id":"UInVM9iGAMv1"},"source":["def loss_function(y_true, y_pred):\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","  \n","  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","      from_logits=True, reduction='none')(y_true, y_pred)\n","\n","  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n","  loss = tf.multiply(loss, mask)\n","\n","  return tf.reduce_mean(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XvFM9ajSVybP"},"source":["### Custom learning rate\n","\n","Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n","\n","$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$"]},{"cell_type":"code","metadata":{"id":"WW3SeLDhAMJd","executionInfo":{"status":"ok","timestamp":1602134535973,"user_tz":-180,"elapsed":519,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super(CustomSchedule, self).__init__()\n","\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","\n","  def __call__(self, step):\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps**-1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"67BoG_UeaHHw"},"source":["sample_learning_rate = CustomSchedule(d_model=128)\n","\n","# plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n","# plt.ylabel(\"Learning Rate\")\n","# plt.xlabel(\"Train Step\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cCqve3kwWCxd"},"source":["### Compile Model\n"]},{"cell_type":"code","metadata":{"id":"1QqojIa5WEQq"},"source":["# learning_rate = CustomSchedule(D_MODEL)\n","# # learning_rate = 0.00005\n","\n","# optimizer = tf.keras.optimizers.Adam(\n","#     learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","# def accuracy(y_true, y_pred):\n","#   # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n","#   y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","#   return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n","\n","# model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vDMd69urLNuc"},"source":["### Fit model\n","\n","Train our transformer by simply calling `model.fit()`"]},{"cell_type":"code","metadata":{"id":"gJJUBOvbACdb"},"source":["# Сохраним веса\n","# model.save_weights('/content/gdrive/My Drive/myChatbot/my_checkpoint/my_checkpoint')\n","# Восстановим веса\n","# model.load_weights('/content/gdrive/My Drive/dialogs/reddit_sentdex/weights/my_checkpoint')\n","# model.load_weights('/content/gdrive/My Drive/myChatbot/my_checkpoint/my_checkpoint')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aQJSin2JPXXU"},"source":["# gpu_info = !nvidia-smi\n","# gpu_info = '\\n'.join(gpu_info)\n","# if gpu_info.find('failed') >= 0:\n","#   print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","#   print('and then re-execute this cell.')\n","# else:\n","#   print(gpu_info)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d7iahRzlLNG2"},"source":["\n","# class CustomCallback(keras.callbacks.Callback):\n","#     def on_epoch_end(self, epoch, logs=None):\n","#         model.save_weights('/content/gdrive/My Drive/dialogs/reddit_sentdex/weights/my_checkpoint')\n","#         # model.save_weights('/content/gdrive/My Drive/myChatbot/my_checkpoint/my_checkpoint')\n","#         # model.save_weights('/content/gdrive/My Drive/HH/my_save/my_checkpoint/my_checkpoint')\n","#         # keys = list(logs.keys())\n","#         # print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n","\n","# EPOCHS = 5\n","\n","\n","# model.fit(dataset,\n","#           epochs=EPOCHS,\n","#           # callbacks=[CustomCallback()]\n","# )\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"88ObUlRDXJB-"},"source":["TPU"]},{"cell_type":"code","metadata":{"id":"VPLtNYfCOZpx","executionInfo":{"status":"error","timestamp":1602109303816,"user_tz":-180,"elapsed":12022481,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"710ef13e-a2f8-4190-ad26-6ba093b32aeb","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["BATCH_SIZE = 128*4\n","# BATCH_SIZE = 128\n","BUFFER_SIZE = 20000\n","\n","# decoder inputs use the previous target as input\n","# remove START_TOKEN from targets\n","dataset = tf.data.Dataset.from_tensor_slices((\n","    {\n","        'inputs': questions,\n","        'dec_inputs': answers[:, :-1]\n","    },\n","    {\n","        'outputs': answers[:, 1:]\n","    },\n","))\n","\n","dataset = dataset.cache()\n","dataset = dataset.shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE)\n","dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","\n","\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","import tensorflow as tf\n","import os\n","import tensorflow_datasets as tfds\n","\n","# Distribution strategies\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)\n","\n","# MNIST model\n","def create_model():\n","\n","  # Hyper-parameters\n","  NUM_LAYERS = 2\n","  D_MODEL = 256\n","  NUM_HEADS = 8\n","  UNITS = 512\n","  DROPOUT = 0.1\n","\n","  return transformer(\n","      vocab_size=VOCAB_SIZE,\n","      num_layers=NUM_LAYERS,\n","      units=UNITS,\n","      d_model=D_MODEL,\n","      num_heads=NUM_HEADS,\n","      dropout=DROPOUT)\n","\n","# Create and train a model\n","strategy = tf.distribute.experimental.TPUStrategy(resolver)\n","with strategy.scope():\n","  model = create_model()\n","\n","  learning_rate = CustomSchedule(D_MODEL)\n","  # learning_rate = 0.00005\n","\n","  optimizer = tf.keras.optimizers.Adam(\n","      learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","  def accuracy(y_true, y_pred):\n","    # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n","    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n","\n","  # model.compile(optimizer=optimizer, loss=loss_function)\n","  model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n","\n","# model.load_weights('/content/gdrive/My Drive/dialogs/reddit_sentdex/weights/DNN_TPU_1024.h5')\n","\n","\n","class CustomCallback(keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        model.save_weights('/content/gdrive/My Drive/dialogs/reddit_big_comments/questions_answers_12/weights/max_DNN_TPU_1024.h5', overwrite=True)\n","\n","EPOCHS = 1000000\n","\n","\n","model.fit(dataset,\n","          epochs=EPOCHS,\n","          # steps_per_epoch = steps_per_epoch\n","          callbacks=[CustomCallback()]\n",")\n","\n","# model.save_weights('/content/gdrive/My Drive/dialogs/reddit_sentdex/weights/DNN_TPU_1024.h5', overwrite=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.50.225.130:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.50.225.130:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.50.225.130:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.50.225.130:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n","WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1000000\n","   1/1413 [..............................] - ETA: 4s - loss: 5.8716 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0067s vs `on_train_batch_end` time: 0.0397s). Check your callbacks.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0067s vs `on_train_batch_end` time: 0.0397s). Check your callbacks.\n"],"name":"stderr"},{"output_type":"stream","text":["1413/1413 [==============================] - 76s 54ms/step - loss: 3.6061 - accuracy: 0.1316\n","Epoch 2/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 2.7668 - accuracy: 0.1864\n","Epoch 3/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 2.5752 - accuracy: 0.2007\n","Epoch 4/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 2.4640 - accuracy: 0.2098\n","Epoch 5/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 2.3776 - accuracy: 0.2171\n","Epoch 6/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 2.3175 - accuracy: 0.2224\n","Epoch 7/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 2.2723 - accuracy: 0.2266\n","Epoch 8/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 2.2365 - accuracy: 0.2299\n","Epoch 9/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 2.2069 - accuracy: 0.2327\n","Epoch 10/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 2.1817 - accuracy: 0.2352\n","Epoch 11/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 2.1606 - accuracy: 0.2371\n","Epoch 12/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 2.1416 - accuracy: 0.2390\n","Epoch 13/1000000\n","1413/1413 [==============================] - 66s 46ms/step - loss: 2.1252 - accuracy: 0.2406\n","Epoch 14/1000000\n","1413/1413 [==============================] - 67s 48ms/step - loss: 2.1105 - accuracy: 0.2420\n","Epoch 15/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 2.0972 - accuracy: 0.2434\n","Epoch 16/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 2.0851 - accuracy: 0.2446\n","Epoch 17/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 2.0742 - accuracy: 0.2456\n","Epoch 18/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 2.0640 - accuracy: 0.2466\n","Epoch 19/1000000\n","1413/1413 [==============================] - 66s 46ms/step - loss: 2.0544 - accuracy: 0.2475\n","Epoch 20/1000000\n","1413/1413 [==============================] - 66s 46ms/step - loss: 2.0457 - accuracy: 0.2485\n","Epoch 21/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 2.0379 - accuracy: 0.2492\n","Epoch 22/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 2.0301 - accuracy: 0.2500\n","Epoch 23/1000000\n","1413/1413 [==============================] - 67s 48ms/step - loss: 2.0230 - accuracy: 0.2508\n","Epoch 24/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 2.0165 - accuracy: 0.2513\n","Epoch 25/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 2.0098 - accuracy: 0.2521\n","Epoch 26/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 2.0040 - accuracy: 0.2527\n","Epoch 27/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9984 - accuracy: 0.2533\n","Epoch 28/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9931 - accuracy: 0.2538\n","Epoch 29/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9878 - accuracy: 0.2544\n","Epoch 30/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9831 - accuracy: 0.2548\n","Epoch 31/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9784 - accuracy: 0.2553\n","Epoch 32/1000000\n","1413/1413 [==============================] - 67s 48ms/step - loss: 1.9738 - accuracy: 0.2557\n","Epoch 33/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9695 - accuracy: 0.2561\n","Epoch 34/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9655 - accuracy: 0.2566\n","Epoch 35/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.9616 - accuracy: 0.2569\n","Epoch 36/1000000\n","1413/1413 [==============================] - 66s 46ms/step - loss: 1.9579 - accuracy: 0.2573\n","Epoch 37/1000000\n","1413/1413 [==============================] - 66s 46ms/step - loss: 1.9543 - accuracy: 0.2577\n","Epoch 38/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.9506 - accuracy: 0.2580\n","Epoch 39/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.9472 - accuracy: 0.2584\n","Epoch 40/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.9444 - accuracy: 0.2589\n","Epoch 41/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.9408 - accuracy: 0.2591\n","Epoch 42/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9380 - accuracy: 0.2593\n","Epoch 43/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.9352 - accuracy: 0.2598\n","Epoch 44/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9322 - accuracy: 0.2600\n","Epoch 45/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9295 - accuracy: 0.2603\n","Epoch 46/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9267 - accuracy: 0.2606\n","Epoch 47/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9239 - accuracy: 0.2609\n","Epoch 48/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9218 - accuracy: 0.2611\n","Epoch 49/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9192 - accuracy: 0.2614\n","Epoch 50/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.9169 - accuracy: 0.2616\n","Epoch 51/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9146 - accuracy: 0.2618\n","Epoch 52/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9125 - accuracy: 0.2621\n","Epoch 53/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.9099 - accuracy: 0.2624\n","Epoch 54/1000000\n","1413/1413 [==============================] - 66s 46ms/step - loss: 1.9080 - accuracy: 0.2626\n","Epoch 55/1000000\n","1413/1413 [==============================] - 66s 46ms/step - loss: 1.9062 - accuracy: 0.2627\n","Epoch 56/1000000\n","1413/1413 [==============================] - 67s 48ms/step - loss: 1.9042 - accuracy: 0.2630\n","Epoch 57/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.9023 - accuracy: 0.2630\n","Epoch 58/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.9002 - accuracy: 0.2633\n","Epoch 59/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8986 - accuracy: 0.2635\n","Epoch 60/1000000\n","1413/1413 [==============================] - 69s 48ms/step - loss: 1.8967 - accuracy: 0.2636\n","Epoch 61/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8950 - accuracy: 0.2639\n","Epoch 62/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8928 - accuracy: 0.2640\n","Epoch 63/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8918 - accuracy: 0.2641\n","Epoch 64/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8900 - accuracy: 0.2645\n","Epoch 65/1000000\n","1413/1413 [==============================] - 67s 48ms/step - loss: 1.8885 - accuracy: 0.2645\n","Epoch 66/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8867 - accuracy: 0.2648\n","Epoch 67/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8851 - accuracy: 0.2649\n","Epoch 68/1000000\n","1413/1413 [==============================] - 66s 46ms/step - loss: 1.8838 - accuracy: 0.2651\n","Epoch 69/1000000\n","1413/1413 [==============================] - 67s 48ms/step - loss: 1.8822 - accuracy: 0.2653\n","Epoch 70/1000000\n","1413/1413 [==============================] - 67s 48ms/step - loss: 1.8803 - accuracy: 0.2654\n","Epoch 71/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8796 - accuracy: 0.2655\n","Epoch 72/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8783 - accuracy: 0.2657\n","Epoch 73/1000000\n","1413/1413 [==============================] - 68s 48ms/step - loss: 1.8769 - accuracy: 0.2659\n","Epoch 74/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8753 - accuracy: 0.2659\n","Epoch 75/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8741 - accuracy: 0.2660\n","Epoch 76/1000000\n","1413/1413 [==============================] - 68s 48ms/step - loss: 1.8726 - accuracy: 0.2664\n","Epoch 77/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8717 - accuracy: 0.2665\n","Epoch 78/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8701 - accuracy: 0.2666\n","Epoch 79/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.8692 - accuracy: 0.2666\n","Epoch 80/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8680 - accuracy: 0.2668\n","Epoch 81/1000000\n","1413/1413 [==============================] - 66s 46ms/step - loss: 1.8664 - accuracy: 0.2670\n","Epoch 82/1000000\n","1413/1413 [==============================] - 67s 48ms/step - loss: 1.8653 - accuracy: 0.2671\n","Epoch 83/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8646 - accuracy: 0.2672\n","Epoch 84/1000000\n","1413/1413 [==============================] - 66s 46ms/step - loss: 1.8634 - accuracy: 0.2673\n","Epoch 85/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.8621 - accuracy: 0.2674\n","Epoch 86/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.8611 - accuracy: 0.2675\n","Epoch 87/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8604 - accuracy: 0.2676\n","Epoch 88/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8592 - accuracy: 0.2677\n","Epoch 89/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8581 - accuracy: 0.2678\n","Epoch 90/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8574 - accuracy: 0.2678\n","Epoch 91/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8562 - accuracy: 0.2681\n","Epoch 92/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8554 - accuracy: 0.2681\n","Epoch 93/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8545 - accuracy: 0.2683\n","Epoch 94/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8535 - accuracy: 0.2683\n","Epoch 95/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8526 - accuracy: 0.2684\n","Epoch 96/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8517 - accuracy: 0.2686\n","Epoch 97/1000000\n","1413/1413 [==============================] - 66s 46ms/step - loss: 1.8507 - accuracy: 0.2686\n","Epoch 98/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8500 - accuracy: 0.2685\n","Epoch 99/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8491 - accuracy: 0.2689\n","Epoch 100/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8484 - accuracy: 0.2689\n","Epoch 101/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8475 - accuracy: 0.2689\n","Epoch 102/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8465 - accuracy: 0.2691\n","Epoch 103/1000000\n","1413/1413 [==============================] - 66s 46ms/step - loss: 1.8455 - accuracy: 0.2693\n","Epoch 104/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8449 - accuracy: 0.2693\n","Epoch 105/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8440 - accuracy: 0.2695\n","Epoch 106/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8436 - accuracy: 0.2695\n","Epoch 107/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8426 - accuracy: 0.2696\n","Epoch 108/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.8417 - accuracy: 0.2697\n","Epoch 109/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8410 - accuracy: 0.2697\n","Epoch 110/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8404 - accuracy: 0.2698\n","Epoch 111/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8397 - accuracy: 0.2698\n","Epoch 112/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.8390 - accuracy: 0.2700\n","Epoch 113/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8382 - accuracy: 0.2700\n","Epoch 114/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8372 - accuracy: 0.2701\n","Epoch 115/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8367 - accuracy: 0.2702\n","Epoch 116/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.8362 - accuracy: 0.2703\n","Epoch 117/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.8354 - accuracy: 0.2703\n","Epoch 118/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8350 - accuracy: 0.2704\n","Epoch 119/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8339 - accuracy: 0.2705\n","Epoch 120/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.8332 - accuracy: 0.2706\n","Epoch 121/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8329 - accuracy: 0.2706\n","Epoch 122/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8321 - accuracy: 0.2707\n","Epoch 123/1000000\n","1413/1413 [==============================] - 69s 49ms/step - loss: 1.8310 - accuracy: 0.2709\n","Epoch 124/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8311 - accuracy: 0.2708\n","Epoch 125/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8304 - accuracy: 0.2708\n","Epoch 126/1000000\n","1413/1413 [==============================] - 68s 48ms/step - loss: 1.8291 - accuracy: 0.2711\n","Epoch 127/1000000\n","1413/1413 [==============================] - 67s 48ms/step - loss: 1.8291 - accuracy: 0.2711\n","Epoch 128/1000000\n","1413/1413 [==============================] - 68s 48ms/step - loss: 1.8286 - accuracy: 0.2712\n","Epoch 129/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8278 - accuracy: 0.2712\n","Epoch 130/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8271 - accuracy: 0.2713\n","Epoch 131/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8268 - accuracy: 0.2713\n","Epoch 132/1000000\n","1413/1413 [==============================] - 69s 49ms/step - loss: 1.8261 - accuracy: 0.2715\n","Epoch 133/1000000\n","1413/1413 [==============================] - 66s 46ms/step - loss: 1.8256 - accuracy: 0.2714\n","Epoch 134/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.8249 - accuracy: 0.2715\n","Epoch 135/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8245 - accuracy: 0.2716\n","Epoch 136/1000000\n","1413/1413 [==============================] - 68s 48ms/step - loss: 1.8239 - accuracy: 0.2716\n","Epoch 137/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8234 - accuracy: 0.2716\n","Epoch 138/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8224 - accuracy: 0.2718\n","Epoch 139/1000000\n","1413/1413 [==============================] - 68s 48ms/step - loss: 1.8222 - accuracy: 0.2719\n","Epoch 140/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8213 - accuracy: 0.2719\n","Epoch 141/1000000\n","1413/1413 [==============================] - 68s 48ms/step - loss: 1.8212 - accuracy: 0.2719\n","Epoch 142/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8206 - accuracy: 0.2720\n","Epoch 143/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8203 - accuracy: 0.2719\n","Epoch 144/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8198 - accuracy: 0.2721\n","Epoch 145/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8190 - accuracy: 0.2722\n","Epoch 146/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8184 - accuracy: 0.2722\n","Epoch 147/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8178 - accuracy: 0.2723\n","Epoch 148/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8181 - accuracy: 0.2723\n","Epoch 149/1000000\n","1413/1413 [==============================] - 68s 48ms/step - loss: 1.8174 - accuracy: 0.2723\n","Epoch 150/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.8166 - accuracy: 0.2725\n","Epoch 151/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8165 - accuracy: 0.2726\n","Epoch 152/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8158 - accuracy: 0.2726\n","Epoch 153/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8155 - accuracy: 0.2727\n","Epoch 154/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8150 - accuracy: 0.2725\n","Epoch 155/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.8144 - accuracy: 0.2727\n","Epoch 156/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8138 - accuracy: 0.2729\n","Epoch 157/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8133 - accuracy: 0.2729\n","Epoch 158/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8129 - accuracy: 0.2728\n","Epoch 159/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8126 - accuracy: 0.2729\n","Epoch 160/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8120 - accuracy: 0.2729\n","Epoch 161/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8120 - accuracy: 0.2731\n","Epoch 162/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8109 - accuracy: 0.2731\n","Epoch 163/1000000\n","1413/1413 [==============================] - 67s 48ms/step - loss: 1.8111 - accuracy: 0.2729\n","Epoch 164/1000000\n","1413/1413 [==============================] - 67s 48ms/step - loss: 1.8105 - accuracy: 0.2731\n","Epoch 165/1000000\n","1413/1413 [==============================] - 66s 46ms/step - loss: 1.8103 - accuracy: 0.2732\n","Epoch 166/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8096 - accuracy: 0.2732\n","Epoch 167/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8092 - accuracy: 0.2732\n","Epoch 168/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.8088 - accuracy: 0.2733\n","Epoch 169/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8084 - accuracy: 0.2733\n","Epoch 170/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.8079 - accuracy: 0.2733\n","Epoch 171/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8077 - accuracy: 0.2735\n","Epoch 172/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8072 - accuracy: 0.2735\n","Epoch 173/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8070 - accuracy: 0.2734\n","Epoch 174/1000000\n","1413/1413 [==============================] - 65s 46ms/step - loss: 1.8063 - accuracy: 0.2736\n","Epoch 175/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8061 - accuracy: 0.2735\n","Epoch 176/1000000\n","1413/1413 [==============================] - 66s 46ms/step - loss: 1.8058 - accuracy: 0.2737\n","Epoch 177/1000000\n","1413/1413 [==============================] - 67s 47ms/step - loss: 1.8055 - accuracy: 0.2737\n","Epoch 178/1000000\n","1413/1413 [==============================] - 66s 47ms/step - loss: 1.8050 - accuracy: 0.2737\n","Epoch 179/1000000\n","1285/1413 [==========================>...] - ETA: 5s - loss: 1.8037 - accuracy: 0.2746"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-98-2166e66740e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m           \u001b[0;31m# steps_per_epoch = steps_per_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCustomCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m )\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"8j1O5vM6JNSe"},"source":["# model.fit(dataset,\n","#           epochs=EPOCHS,\n","#           # steps_per_epoch = steps_per_epoch\n","#           # callbacks=[CustomCallback()]\n","# )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MjuPlMGUfXtS","executionInfo":{"status":"ok","timestamp":1602134878375,"user_tz":-180,"elapsed":1317,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["# Load\n","tokenizer = tfds.features.text.SubwordTextEncoder.load_from_file('/content/gdrive/My Drive/dialogs/reddit_big_comments/questions_answers_12/tokenizer')\n","\n","# Define start and end token to indicate the start and end of a sentence\n","START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n","\n","# Vocabulary size plus start and end token\n","VOCAB_SIZE = tokenizer.vocab_size + 2"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"25ti9oNq5ebx","executionInfo":{"status":"ok","timestamp":1602134893280,"user_tz":-180,"elapsed":2901,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["def create_model():\n","\n","  # Hyper-parameters\n","  NUM_LAYERS = 2\n","  D_MODEL = 256\n","  NUM_HEADS = 8\n","  UNITS = 512\n","  DROPOUT = 0.1\n","\n","  return transformer(\n","      vocab_size=VOCAB_SIZE,\n","      num_layers=NUM_LAYERS,\n","      units=UNITS,\n","      d_model=D_MODEL,\n","      num_heads=NUM_HEADS,\n","      dropout=DROPOUT)\n","\n","model = create_model()\n","\n","MAX_LENGTH = 14\n","\n","\n","# optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","# model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"opFkJIxsZj4E","executionInfo":{"status":"ok","timestamp":1602134899329,"user_tz":-180,"elapsed":1074,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["model.load_weights('/content/gdrive/My Drive/dialogs/reddit_big_comments/questions_answers_12/weights/max_DNN_TPU_1024.h5')"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wRm1M5n1gCdT"},"source":["Prediction on CPU"]},{"cell_type":"code","metadata":{"id":"_NjsS3zuAbRn","executionInfo":{"status":"ok","timestamp":1602134901831,"user_tz":-180,"elapsed":564,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["def evaluate(sentence):\n","\n","  sentence = tf.expand_dims(\n","      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n","\n","  output = tf.expand_dims(START_TOKEN, 0)\n","\n","  for i in range(MAX_LENGTH):\n","    predictions = model(inputs=[sentence, output], training=False)\n","    # print('predictions: {}'.format(sentence))\n","\n","    # predictions = cpu_model(inputs=[sentence, output], training=False)\n","\n","    # select the last word from the seq_len dimension\n","    predictions = predictions[:, -1:, :]\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","\n","    # return the result if the predicted_id is equal to the end token\n","    if tf.equal(predicted_id, END_TOKEN[0]):\n","      break\n","\n","    # concatenated the predicted_id to the output which is given to the decoder\n","    # as its input.\n","    output = tf.concat([output, predicted_id], axis=-1)\n","\n","  return tf.squeeze(output, axis=0)\n","\n","\n","def predict(sentence):\n","  sentence = x_preprocess_sentence(sentence)\n","  if len(sentence.split(' ')) > 12:\n","    return 'length should be not more than 12'\n","\n","  my_answer = ''\n","  for h_t in hand_translate:\n","    if h_t in sentence:\n","      if ('hello' in sentence) or ('hi' in sentence):\n","        my_answer = my_answer + 'Hi. '\n","      my_answer = my_answer + hand_translate[h_t]\n","      break\n","  if my_answer != '':\n","    return my_answer\n","\n","  \n","\n","  prediction = evaluate(sentence)\n","\n","  predicted_sentence = tokenizer.decode(\n","      [i for i in prediction if i < tokenizer.vocab_size])\n","\n","  return predicted_sentence"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"efp7yXIh1dJX","executionInfo":{"status":"ok","timestamp":1602134987426,"user_tz":-180,"elapsed":569,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}}},"source":["hand_translate = {\n","    # 'how are you':\"I'm fine. Thank you\",\n","    # \"are you robot\":\"Yes. I'm robot. My name is Roborobot\",\n","    # \"what is your name\":\"my name is Roborobot\",\n","    # \"what is your profession\":\"i work as bot\",\n","    # \"where you from\":\"i from Mars\"\n","}"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"pbgDcUodbRhv"},"source":["# tokenizer.word_index"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9J3Jdtk2P-RT"},"source":["Let's test our model!"]},{"cell_type":"code","metadata":{"id":"beGGXSsGvtq8","executionInfo":{"status":"ok","timestamp":1602134945227,"user_tz":-180,"elapsed":1962,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"75de09eb-25dc-4709-fd24-1022b03d61a3","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["predict('do you want fuck me?')"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'i want to fuck me in the ass .'"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"6IeMSGEgRTvC","executionInfo":{"status":"ok","timestamp":1602134996073,"user_tz":-180,"elapsed":1571,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"20fbeb33-e39f-42cc-881b-beda621a52d0","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["predict('hello.how are you')"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'i am gonna take my money to get her bed .'"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"48QfbHzMEhsG","executionInfo":{"status":"ok","timestamp":1602135070985,"user_tz":-180,"elapsed":750,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"12e64c43-acbe-42ed-b19d-cb455cc4d590","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["predict('are you robot?')"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'i am .'"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"dQFgqEaoE994","executionInfo":{"status":"ok","timestamp":1602135093283,"user_tz":-180,"elapsed":1641,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"a829ace8-850a-4927-d756-fd79dca4ad81","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["predict('what kind of work do you do?')"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'i am guessing he is a real human being .'"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"3wnZlRj6BtM2","executionInfo":{"status":"ok","timestamp":1602135141542,"user_tz":-180,"elapsed":1770,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"1dd5534b-c8aa-40e8-aeb1-4bd470b5a362","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["predict('are you ready?')"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'i am not ready to go .'"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"VLcieHeEBy9n","executionInfo":{"status":"ok","timestamp":1602135154019,"user_tz":-180,"elapsed":1087,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"50c36cd0-8c44-405b-b78d-7a639398ff61","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["predict('hi')"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'hi'"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"8KjqYyJBCdxc","executionInfo":{"status":"ok","timestamp":1602135162991,"user_tz":-180,"elapsed":1740,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"ff6131d5-e9b5-47dd-c4a9-e3ad3688bca2","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["predict('what is your profession?')"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'i am a professional redditor .'"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"wHZdYH-PCR2s","executionInfo":{"status":"ok","timestamp":1602135179185,"user_tz":-180,"elapsed":1094,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"30267353-21e7-4628-9eec-049ce0c0bf16","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["predict('how old are you?')"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'i am .'"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"Wt6wWyzGf7m4","executionInfo":{"status":"ok","timestamp":1602135229007,"user_tz":-180,"elapsed":1322,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"7909679c-6a48-402a-ad85-0324e026730f","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["predict('where you from?')"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'i am guessing the other one is a little bit older'"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"WHbYa64qCCDo","executionInfo":{"status":"ok","timestamp":1602135243076,"user_tz":-180,"elapsed":1192,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"507390b1-8ae9-44a1-cb4a-e569c4709f61","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["predict('where do you live?')"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'i am guessing he is a real human being .'"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"jJeIvmmAB5qS","executionInfo":{"status":"ok","timestamp":1602135264188,"user_tz":-180,"elapsed":1244,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"7edd3027-0853-45b9-a689-f1c45a157b0b","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["predict('what is your name?')"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'i am a little bit of a little bit of both .'"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"ivVgU6ydRV8R","executionInfo":{"status":"ok","timestamp":1602135303885,"user_tz":-180,"elapsed":1026,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"5b54a751-296c-406d-c46c-0cc1eee2ba4d","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["predict(\"i have apple\")"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'i have got a apple .'"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"s5zG7i8KAtRU","executionInfo":{"status":"ok","timestamp":1602135328980,"user_tz":-180,"elapsed":750,"user":{"displayName":"Pavel Kolodeznyy","photoUrl":"","userId":"11463323471728000280"}},"outputId":"4a0bc345-d85f-4f0a-c988-00c976dd35f8","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["predict('how make money?')\n","  # print(sentence)"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'how make money . money .'"]},"metadata":{"tags":[]},"execution_count":46}]}]}